import pandas as pd
import numpy as np
import os
import json

# ==============================================================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
# ==============================================================================
DATA_FILE = 'reference_candles_15days_20251225.csv'
PATTERNS_FILE = 'successful_candles.csv'

print('=' * 90)
print('ğŸ›¡ï¸  Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (Patterns + Crawl Filter) Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª 15 ÙŠÙˆÙ…')
print('=' * 90)

# ==============================================================================
# 2. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ù†Ø·Ù‚ (Ù†Ø³Ø®Ø© Ø·Ø¨Ù‚ Ø§Ù„Ø£ØµÙ„ Ù…Ù† reeshah.py)
# ==============================================================================

def load_patterns():
    if not os.path.exists(PATTERNS_FILE):
        print("âŒ Ù…Ù„Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return {}, {}

    df = pd.read_csv(PATTERNS_FILE)
    df.columns = df.columns.str.strip().str.lower()
    
    # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
    df = df[~df['symbol'].str.upper().isin(['NBY', 'SIDU'])]

    patterns = {}
    pattern_metrics = {}

    for symbol, group in df.groupby('symbol'):
        group = group.sort_values('time')
        if len(group) >= 6:
            candles = group.iloc[:6][['open', 'high', 'low', 'close']].values

            candle_details = []
            for i in range(len(candles)):
                o, h, l, c = candles[i]
                body_pct = (c - o) / o * 100
                direction = 1 if c >= o else -1
                body_size = abs(body_pct)

                candle_details.append({
                    'direction': direction,
                    'body_pct': body_pct,
                    'body_size': body_size,
                    'open': o, 'high': h, 'low': l, 'close': c
                })

            patterns[symbol] = candles
            pattern_metrics[symbol] = {
                'candle_details': candle_details,
                'avg_body': np.mean([cd['body_size'] for cd in candle_details])
            }
            
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(patterns)} Ù†Ù…Ø· Ù…Ø±Ø¬Ø¹ÙŠ")
    return patterns, pattern_metrics

def calculate_similarity(current_candles, reference_patterns, pattern_metrics):
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    current_details = []
    for i in range(len(current_candles)):
        o, h, l, c = current_candles[i]
        body_pct = (c - o) / o * 100
        direction = 1 if c >= o else -1
        body_size = abs(body_pct)

        current_details.append({
            'direction': direction,
            'body_pct': body_pct,
            'body_size': body_size,
            'open': o, 'high': h, 'low': l, 'close': c
        })

    # ğŸš¨ Ø´Ø±Ø· Ø¥Ù„Ø²Ø§Ù…ÙŠ: Ø§Ù„Ø³Ù‡Ù… ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØµØ§Ø¹Ø¯ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…!
    curr_start = current_details[0]['open']
    curr_end = current_details[-1]['close']
    curr_trend = (curr_end - curr_start) / curr_start * 100

    if curr_trend <= 0:
        return 0, "None"

    best_score = 0
    best_name = "None"

    for name, ref_candles in reference_patterns.items():
        if name not in pattern_metrics: continue

        ref_details = pattern_metrics[name]['candle_details']
        compare_len = min(len(current_details), len(ref_details))
        if compare_len < 3: continue

        # 1ï¸âƒ£ ÙØ­Øµ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
        direction_matches = 0
        for i in range(compare_len):
            if current_details[i]['direction'] == ref_details[i]['direction']:
                direction_matches += 1

        direction_ratio = direction_matches / compare_len
        if direction_ratio < 0.67: continue

        direction_score = direction_ratio * 100

        # 2ï¸âƒ£ ÙØ­Øµ ØªØ´Ø§Ø¨Ù‡ Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø´Ù…ÙˆØ¹
        size_penalties = 0
        for i in range(compare_len):
            curr_size = current_details[i]['body_size']
            ref_size = ref_details[i]['body_size']

            if ref_size > 0:
                size_diff = abs(curr_size - ref_size) / max(ref_size, 0.1)
            else:
                size_diff = curr_size

            if size_diff > 1.0:
                size_penalties += min(size_diff - 1.0, 1.0) * 20

        size_score = max(0, 100 - size_penalties)

        final_score = (direction_score * 0.60 + size_score * 0.40)

        if final_score > best_score:
            best_score = final_score
            best_name = name

    return best_score, best_name

# ==============================================================================
# 3. ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
# ==============================================================================

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
if not os.path.exists(DATA_FILE):
    print(f"âŒ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª {DATA_FILE} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
    exit()

print("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©...")
df_all = pd.read_csv(DATA_FILE)
df_all['date'] = pd.to_datetime(df_all['date'])

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ù…Ù† UTC Ø¥Ù„Ù‰ Ù†ÙŠÙˆÙŠÙˆØ±Ùƒ (America/New_York)
# Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© UTC (Ù„Ø£Ù†Ù‡Ø§ ØªØ¨Ø¯Ø£ 14:30)
try:
    if df_all['date'].dt.tz is None:
        df_all['date'] = df_all['date'].dt.tz_localize('UTC')
    
    df_all['date'] = df_all['date'].dt.tz_convert('America/New_York')
    print("âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø¥Ù„Ù‰ Ù†ÙŠÙˆÙŠÙˆØ±Ùƒ")
except Exception as e:
    print(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª: {e}")

print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df_all)} ØµÙ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

patterns, pattern_metrics = load_patterns()

results = []
filtered_count = 0

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø³Ù‡Ù… ÙˆØ§Ù„ÙŠÙˆÙ…
# Ù†Ø­ØªØ§Ø¬ Ø¹Ù…ÙˆØ¯ Ù„Ù„ÙŠÙˆÙ… ÙÙ‚Ø·
df_all['day_str'] = df_all['date'].dt.strftime('%Y-%m-%d')

grouped = df_all.groupby(['symbol', 'day_str'])

print(f"ğŸ” Ø¬Ø§Ø±ÙŠ ÙØ­Øµ {len(grouped)} ÙŠÙˆÙ… ØªØ¯Ø§ÙˆÙ„...")

for (symbol, day), day_data in grouped:
    day_data = day_data.sort_values('date')
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…ÙˆØ¹ Ø§Ù„ØµØ¨Ø§Ø­ (09:30 - 09:55)
    # Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ØªÙˆÙ‚ÙŠØª Ù†ÙŠÙˆÙŠÙˆØ±Ùƒ Ø£Ùˆ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ù„Ù
    # Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø© (HH:MM)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª Ù„ÙÙ„ØªØ±Ø© Ø³Ù‡Ù„Ø©
    day_data['time_str'] = day_data['date'].dt.strftime('%H:%M')
    
    morning_mask = day_data['time_str'].isin(['09:30', '09:35', '09:40', '09:45', '09:50', '09:55'])
    morning_candles = day_data[morning_mask]
    
    if len(morning_candles) < 4: continue # Ù†Ø­ØªØ§Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ 4 Ø´Ù…ÙˆØ¹ Ù„Ù„Ø­ÙƒÙ…
    
    # 1. ÙÙ„ØªØ± Ø§Ù„Ø²Ø­Ù (Crawl Filter)
    # Ù…ØªÙˆØ³Ø· Ø¬Ø³Ù… Ø§Ù„Ø´Ù…Ø¹Ø© < 1.0%
    candles_vals = morning_candles[['open', 'high', 'low', 'close']].values
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø£ØµÙØ§Ø±
    valid_candles = [c for c in candles_vals if c[0] > 0 and c[3] > 0]
    if len(valid_candles) < 4: continue
    
    avg_body = np.mean([abs(c[3]-c[0])/c[0]*100 for c in valid_candles])
    
    if np.isnan(avg_body) or avg_body >= 1.0:
        filtered_count += 1
        continue
        
    # 2. Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø·
    score, name = calculate_similarity(valid_candles, patterns, pattern_metrics)
    
    if score >= 70:
        # âœ… Ø¥Ø´Ø§Ø±Ø© Ø¯Ø®ÙˆÙ„!
        entry_price = valid_candles[-1][3] # Ø¥ØºÙ„Ø§Ù‚ Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© ØµØ¨Ø§Ø­ÙŠØ©
        
        if entry_price <= 0: continue
        
        entry_time = morning_candles.iloc[-1]['date']
        
        # ÙØ­Øµ Ù…Ø§ Ø­Ø¯Ø« Ø¨Ù‚ÙŠØ© Ø§Ù„ÙŠÙˆÙ…
        rest_of_day = day_data[day_data['date'] > entry_time]
        
        if len(rest_of_day) == 0: continue
        
        max_price = rest_of_day['high'].max()
        min_price = rest_of_day['low'].min()
        
        max_gain = (max_price - entry_price) / entry_price * 100
        max_loss = (min_price - entry_price) / entry_price * 100
        
        if np.isnan(max_gain) or np.isnan(max_loss): continue

        results.append({
            'date': day,
            'symbol': symbol,
            'pattern': name,
            'score': score,
            'avg_body': avg_body,
            'max_gain': max_gain,
            'max_loss': max_loss
        })

# ==============================================================================
# 4. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
# ==============================================================================
print('\n' + '=' * 90)
print('ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (15 ÙŠÙˆÙ…)')
print('=' * 90)

total_signals = len(results)
if total_signals > 0:
    avg_gain = np.mean([r['max_gain'] for r in results])
    avg_loss = np.mean([r['max_loss'] for r in results])
    
    wins_3 = len([r for r in results if r['max_gain'] >= 3])
    wins_5 = len([r for r in results if r['max_gain'] >= 5])
    wins_10 = len([r for r in results if r['max_gain'] >= 10])
    
    losses_2 = len([r for r in results if r['max_loss'] <= -2])
    losses_5 = len([r for r in results if r['max_loss'] <= -5])
    
    print(f"ğŸ”¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {total_signals}")
    print(f"ğŸ§¹ ØªÙ… Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ {filtered_count} Ø­Ø§Ù„Ø© Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (Spikes)")
    print(f"ğŸ“ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ø£Ù‚ØµÙ‰: {avg_gain:+.2f}%")
    print(f"ğŸ“‰ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù‚ØµÙˆÙ‰: {avg_loss:.2f}%")
    print("-" * 40)
    print(f"âœ… Ù†Ø³Ø¨Ø© Ù†Ø¬Ø§Ø­ (â‰¥3%): {wins_3}/{total_signals} ({wins_3/total_signals*100:.1f}%)")
    print(f"ğŸš€ Ù†Ø³Ø¨Ø© Ù†Ø¬Ø§Ø­ (â‰¥5%): {wins_5}/{total_signals} ({wins_5/total_signals*100:.1f}%)")
    print(f"ğŸ’ Ù†Ø³Ø¨Ø© Ù†Ø¬Ø§Ø­ (â‰¥10%): {wins_10}/{total_signals} ({wins_10/total_signals*100:.1f}%)")
    print("-" * 40)
    print(f"âš ï¸ Ù…Ø®Ø§Ø·Ø±Ø© (Ù‡Ø¨ÙˆØ· > 2%): {losses_2}/{total_signals} ({losses_2/total_signals*100:.1f}%)")
    print(f"ğŸ’€ Ù…Ø®Ø§Ø·Ø±Ø© (Ù‡Ø¨ÙˆØ· > 5%): {losses_5}/{total_signals} ({losses_5/total_signals*100:.1f}%)")
    
    print('\nğŸ† Ø£ÙØ¶Ù„ Ø§Ù„ØµÙÙ‚Ø§Øª:')
    top_gains = sorted(results, key=lambda x: x['max_gain'], reverse=True)[:10]
    for r in top_gains:
        print(f"   {r['date']} | {r['symbol']:<5} | {r['pattern']:<10} | Ø±Ø¨Ø­: {r['max_gain']:+.1f}% | Ø®Ø³Ø§Ø±Ø©: {r['max_loss']:.1f}% | Body: {r['avg_body']:.2f}%")

    print('\nğŸ“‰ Ø£Ø³ÙˆØ£ Ø§Ù„ØµÙÙ‚Ø§Øª:')
    worst_losses = sorted(results, key=lambda x: x['max_loss'])[:5]
    for r in worst_losses:
        print(f"   {r['date']} | {r['symbol']:<5} | {r['pattern']:<10} | Ø±Ø¨Ø­: {r['max_gain']:+.1f}% | Ø®Ø³Ø§Ø±Ø©: {r['max_loss']:.1f}% | Body: {r['avg_body']:.2f}%")

else:
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø´Ø±ÙˆØ·.")
