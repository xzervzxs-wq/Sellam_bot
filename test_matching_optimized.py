#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø§Ø®ØªØ¨Ø§Ø± Strict Rhythm - Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø© ÙˆØ³Ø±ÙŠØ¹Ø©
"""
import pandas as pd
import numpy as np
import time

start_time = time.time()

print("\n" + "="*70)
print("ğŸ§¬ Ø§Ø®ØªØ¨Ø§Ø± Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Strict Rhythm (Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©)")
print("="*70)

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
print("\nğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
df_test = pd.read_csv('test_candles_20251223_170248.csv')
df_patterns = pd.read_csv('successful_candles.csv')
df_patterns.columns = df_patterns.columns.str.strip().str.lower()

print(f"  âœ… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {len(df_test)} ØµÙ")
print(f"  âœ… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {len(df_patterns)} ØµÙ")
print(f"  âœ… Ø£Ø³Ù‡Ù… ÙØ±ÙŠØ¯Ø©: {df_test['symbol'].nunique()} ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±ØŒ {df_patterns['symbol'].nunique()} ÙÙŠ Ø§Ù„Ø£Ù†Ù…Ø§Ø·")

# 2. Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
def extract_dna(candles):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ù…Ø¶ Ø§Ù„Ù†ÙˆÙˆÙŠ"""
    dna = []
    if isinstance(candles, pd.DataFrame):
        candles = candles[['open', 'high', 'low', 'close']].values.tolist()
    
    for c in candles:
        o, h, l, cl = float(c[0]), float(c[1]), float(c[2]), float(c[3])
        tr = h - l
        if tr == 0: tr = 0.0001
        
        dna.append({
            'body_r': abs(cl - o) / tr,
            'upper_r': (h - max(o, cl)) / tr,
            'lower_r': (min(o, cl) - l) / tr,
            'dir': 1 if cl >= o else -1,
            'size': (abs(cl - o) / o * 100) if o > 0 else 0
        })
    return dna

def calculate_similarity(curr_dna, pattern_dna):
    """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Strict Rhythm"""
    if len(curr_dna) != len(pattern_dna):
        return 0
    
    score = 100.0
    for curr, pattern in zip(curr_dna, pattern_dna):
        # 1. Ø§ØªØ¬Ø§Ù‡ Ù…Ø®ØªÙ„Ù = Ø¹Ù‚ÙˆØ¨Ø© ÙƒØ¨ÙŠØ±Ø©
        if curr['dir'] != pattern['dir']:
            score -= 50
        
        # 2. ÙØ±Ù‚ ÙÙŠ Ø­Ø¬Ù… Ø§Ù„Ø¬Ø³Ù…
        body_diff = abs(curr['body_r'] - pattern['body_r'])
        if body_diff > 0.15:
            score -= body_diff * 30
        
        # 3. ÙØ±Ù‚ ÙÙŠ Ø­Ø¬Ù… Ø§Ù„Ø´Ù…Ø¹Ø© (Ù…Ø¶Ø®Ø§Øª Ø§Ù†ÙØ¬Ø§Ø±ÙŠØ©)
        size_diff = abs(curr['size'] - pattern['size'])
        if size_diff > 0.4:
            score -= (size_diff - 0.4) * 20
    
    return max(0, score)

# 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
print("\nğŸ“Š Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ DNA Ù„Ù„Ø£Ù†Ù…Ø§Ø·...")
patterns_dict = {}
for symbol, group in df_patterns.groupby('symbol'):
    if len(group) >= 6:
        candles = group.iloc[:6][['open', 'high', 'low', 'close']].values
        patterns_dict[symbol] = extract_dna(candles)

print(f"  âœ… Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {len(patterns_dict)}")

# 4. Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
print("\nğŸ“Š Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡...")
results = []
all_scores = []

stocks = df_test['symbol'].unique()
print(f"  ğŸ” Ø¬Ø§Ø±ÙŠ ÙØ­Øµ {len(stocks)} Ø³Ù‡Ù…...")

for idx, stock in enumerate(stocks):
    stock_data = df_test[df_test['symbol'] == stock].sort_values('time')
    
    if len(stock_data) < 6:
        continue
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ DNA
    candles = stock_data.head(6)[['open', 'high', 'low', 'close']].values
    curr_dna = extract_dna(candles)
    
    # Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    scores = {}
    for pname, pdna in patterns_dict.items():
        scores[pname] = calculate_similarity(curr_dna, pdna)
    
    if scores:
        avg_score = sum(scores.values()) / len(scores)
        max_score = max(scores.values())
        best_pattern = max(scores, key=scores.get)
        
        all_scores.append(avg_score)
        results.append({
            'symbol': stock,
            'avg_match': avg_score,
            'best_match': max_score,
            'best_pattern': best_pattern
        })

print(f"\n  âœ… Ù†ØªØ§Ø¦Ø¬: {len(results)} Ø³Ù‡Ù… ØªÙ… ÙØ­ØµÙ‡Ù…")

# 5. Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
print("\n" + "="*70)
print("ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
print("="*70)

if all_scores:
    avg_all = sum(all_scores) / len(all_scores)
    print(f"  ğŸ“Š Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©: {avg_all:.2f}%")
    print(f"  ğŸ” Ø£Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø©: {max(all_scores):.2f}%")
    print(f"  ğŸ”» Ø£Ù‚Ù„ Ù…Ø·Ø§Ø¨Ù‚Ø©: {min(all_scores):.2f}%")
    
    excellent = sum(1 for s in all_scores if s >= 90)
    good = sum(1 for s in all_scores if 70 <= s < 90)
    okay = sum(1 for s in all_scores if 50 <= s < 70)
    poor = sum(1 for s in all_scores if s < 50)
    
    print(f"\n  ğŸ“Š Ø§Ù„ØªÙˆØ²ÙŠØ¹:")
    print(f"    â­â­â­â­â­ Ù…Ù…ØªØ§Ø² (90%+):     {excellent} ({100*excellent/len(all_scores):.1f}%)")
    print(f"    â­â­â­â­   Ø¬ÙŠØ¯ (70-90%):   {good} ({100*good/len(all_scores):.1f}%)")
    print(f"    â­â­â­     Ø­Ø³Ù† (50-70%):   {okay} ({100*okay/len(all_scores):.1f}%)")
    print(f"    â­       Ø¶Ø¹ÙŠÙ (<50%):    {poor} ({100*poor/len(all_scores):.1f}%)")

# 6. Ø£ÙØ¶Ù„ Ø§Ù„Ø£Ø³Ù‡Ù…
print("\n" + "="*70)
print("ğŸ† Ø£ÙØ¶Ù„ 20 Ø³Ù‡Ù… Ù…Ø·Ø§Ø¨Ù‚Ø©:")
print("="*70)

df_results = pd.DataFrame(results)
df_results_sorted = df_results.sort_values('avg_match', ascending=False)

print(f"\n{'#':<3} {'Symbol':<10} {'Avg %':<10} {'Best %':<10} {'Pattern':<15}")
print("-" * 70)

for idx, (_, row) in enumerate(df_results_sorted.head(20).iterrows(), 1):
    print(f"{idx:<3} {row['symbol']:<10} {row['avg_match']:>8.1f}% {row['best_match']:>8.1f}% {row['best_pattern']:<15}")

# 7. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
output_file = 'matching_results_optimized.csv'
df_results_sorted.to_csv(output_file, index=False)
print(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {output_file}")

elapsed = time.time() - start_time
print(f"\nâ±ï¸  Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªØºØ±Ù‚: {elapsed:.2f} Ø«Ø§Ù†ÙŠØ©")
print("\nâœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­!")
