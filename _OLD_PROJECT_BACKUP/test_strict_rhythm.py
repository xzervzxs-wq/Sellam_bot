#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø§Ø®ØªØ¨Ø§Ø± Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Strict Rhythm Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± ÙØ¹Ù„ÙŠØ©
"""
import pandas as pd
import sys
sys.path.insert(0, '/workspaces/Sellam_bot')

from reeshah import (
    load_successful_patterns,
    extract_candle_dna,
    calculate_structural_similarity
)

def test_matching_on_file(test_file, output_file=None):
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª"""
    
    print("\n" + "="*70)
    print("ğŸ§¬ Ø§Ø®ØªØ¨Ø§Ø± Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Strict Rhythm")
    print("="*70)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    print("\nğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    try:
        df_test = pd.read_csv(test_file)
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df_test)} ØµÙ Ù…Ù† {test_file}")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")
        return None
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
    print("\nğŸ¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø§Ø¬Ø­Ø©...")
    patterns = load_successful_patterns()
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(patterns)} Ù†Ù…Ø· Ù†Ø§Ø¬Ø­")
    
    # Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„ÙØ±ÙŠØ¯Ø©
    stocks = df_test['symbol'].unique()
    print(f"âœ… Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„ÙØ±ÙŠØ¯Ø©: {len(stocks)}")
    
    # Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
    results = []
    
    print("\n" + "="*70)
    print("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©...")
    print("="*70)
    
    total_matches = 0
    all_scores = []
    
    for idx, stock in enumerate(stocks, 1):
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø´Ù…ÙˆØ¹ Ù‡Ø°Ø§ Ø§Ù„Ø³Ù‡Ù…
        stock_data = df_test[df_test['symbol'] == stock].sort_values('time')
        
        if len(stock_data) < 6:
            continue
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø´Ù…ÙˆØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø© (Ø£ÙˆÙ„ 6)
        sample_candles = stock_data.head(6).to_dict('records')
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        similarity_scores = calculate_structural_similarity(sample_candles, patterns)
        
        if similarity_scores:
            avg_score = sum(similarity_scores.values()) / len(similarity_scores)
            max_score = max(similarity_scores.values())
            min_score = min(similarity_scores.values())
            
            all_scores.append(avg_score)
            
            # Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ Ù†Ù…Ø·
            best_pattern = max(similarity_scores, key=similarity_scores.get)
            best_match = similarity_scores[best_pattern]
            
            results.append({
                'symbol': stock,
                'avg_match': avg_score,
                'best_match': best_match,
                'best_pattern': best_pattern,
                'num_patterns': len(similarity_scores)
            })
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ„ 50 Ø³Ù‡Ù…
            if idx % 50 == 0 or idx == len(stocks):
                status = f"{stock:<10} Avg: {avg_score:6.1f}% | Best: {best_match:6.1f}% ({best_pattern})"
                print(f"{status:<70} ({idx}/{len(stocks)})")
                total_matches += 1
    
    # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    print("\n" + "="*70)
    print("ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©:")
    print("="*70)
    
    if all_scores:
        avg_all = sum(all_scores) / len(all_scores)
        max_all = max(all_scores)
        min_all = min(all_scores)
        
        print(f"  ğŸ“ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©: {avg_all:.2f}%")
        print(f"  ğŸ” Ø£Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø©: {max_all:.2f}%")
        print(f"  ğŸ”» Ø£Ù‚Ù„ Ù…Ø·Ø§Ø¨Ù‚Ø©: {min_all:.2f}%")
        print(f"  ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù…Ø®ØªØ¨Ø±Ø©: {len(results)}")
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù†Ø³Ø¨
        excellent = len([s for s in all_scores if s >= 90])
        good = len([s for s in all_scores if 70 <= s < 90])
        okay = len([s for s in all_scores if 50 <= s < 70])
        poor = len([s for s in all_scores if s < 50])
        
        print(f"\n  ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù†Ø³Ø¨:")
        print(f"    â­â­â­â­â­ Ù…Ù…ØªØ§Ø² (90%+):   {excellent} ({100*excellent/len(all_scores):.1f}%)")
        print(f"    â­â­â­â­   Ø¬ÙŠØ¯ (70-90%): {good} ({100*good/len(all_scores):.1f}%)")
        print(f"    â­â­â­     Ø­Ø³Ù† (50-70%): {okay} ({100*okay/len(all_scores):.1f}%)")
        print(f"    â­       Ø¶Ø¹ÙŠÙ (<50%):  {poor} ({100*poor/len(all_scores):.1f}%)")
    
    # Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø£ÙØ¶Ù„
    if results:
        print("\n" + "="*70)
        print("ğŸ† Ø£ÙØ¶Ù„ 15 Ø£Ø³Ù‡Ù… Ù…Ø·Ø§Ø¨Ù‚Ø©:")
        print("="*70)
        
        df_results = pd.DataFrame(results)
        top_15 = df_results.nlargest(15, 'avg_match')
        
        print(f"\n{'#':<3} {'Symbol':<10} {'Avg Match':<12} {'Best Match':<12} {'Best Pattern':<15}")
        print("-" * 70)
        
        for idx, row in enumerate(top_15.values, 1):
            print(f"{idx:<3} {row[0]:<10} {row[1]:>10.1f}% {row[2]:>10.1f}% {row[3]:<15}")
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    if output_file and results:
        df_results = pd.DataFrame(results)
        df_results = df_results.sort_values('avg_match', ascending=False)
        df_results.to_csv(output_file, index=False)
        print(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {output_file}")
    
    return results

if __name__ == '__main__':
    test_file = '/workspaces/Sellam_bot/test_candles_20251223_170248.csv'
    output_file = '/workspaces/Sellam_bot/matching_results_20251223.csv'
    
    test_matching_on_file(test_file, output_file)
