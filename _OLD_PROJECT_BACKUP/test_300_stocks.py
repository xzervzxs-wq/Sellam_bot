import pandas as pd
import requests
import os
import io
import numpy as np
from datetime import datetime, time, timedelta
import pytz
from dotenv import load_dotenv
import time as time_module

# ==============================================================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# ==============================================================================
load_dotenv()
EODHD_API_KEY = os.getenv("EODHD_API_KEY", "68c0ad0b52af78.88121932")
FINVIZ_COOKIE = """chartsTheme=dark; notice-newsletter=show; .ASPXAUTH=C7E2E86BC876CD078E1DC69C25671D062A909C67501ECF211333FAAD7F54A40FE9B6772EF4E88ED21E26C6C99BCAE5C39C5C8D598CD73357A5FCB4B556AD83E55002A827606EFFFE1F1315C9E8A4E05BC99B517D7E533905EE95F029D8FE0B930EC18E2E5F5037693AE688694BFDFDD82DADE25BA4063B448D18DDC85EAB40FD9D717716F2FEABA2A813D932072BFF5C6F723BACD8D3E4CA5161C3B1E0FF3088C9CC8AA7E67C3A4C94EA5122A68D9ADC7F85B091D98A31BF66F654490F1F7601FA7E420E3ECAF266BF62C1A7C9733A57BC866F92; survey_dialog_cohort=0"""

FINVIZ_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Cookie": FINVIZ_COOKIE
}

ny_tz = pytz.timezone('America/New_York')
SUCCESSFUL_PATTERNS_FILE = "successful_candles.csv"

# ==============================================================================
# Ø¯Ø§Ù„Ø© ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
# ==============================================================================
def normalize_pattern(candles):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø¥Ù„Ù‰ Ø¨ØµÙ…Ø© Ø±Ù‚Ù…ÙŠØ© (0-1)"""
    candles = np.array(candles, dtype=float)
    min_val = np.min(candles)
    max_val = np.max(candles)
    if max_val == min_val: 
        return np.zeros_like(candles)
    return (candles - min_val) / (max_val - min_val)

# ==============================================================================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
# ==============================================================================
def load_successful_patterns():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ù…Ù† successful_candles.csv"""
    if not os.path.exists(SUCCESSFUL_PATTERNS_FILE):
        print(f"âš ï¸ Ù…Ù„Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        return {}
    
    try:
        df = pd.read_csv(SUCCESSFUL_PATTERNS_FILE)
        df.columns = df.columns.str.strip().str.lower()
        
        patterns = {}
        for symbol, group in df.groupby('symbol'):
            group = group.sort_values('time')
            if len(group) >= 6:
                candles = group.iloc[:6][['open', 'high', 'low', 'close']].values
                patterns[symbol] = normalize_pattern(candles)
        
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(patterns)} Ù†Ù…Ø· ØªØ§Ø±ÙŠØ®ÙŠ")
        return patterns
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {e}")
        return {}

# ==============================================================================
# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø´Ù…Ø¹Ø©
# ==============================================================================
def get_candle_metrics(candles):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§ÙŠÙŠØ³: Ø­Ø¬Ù… Ø§Ù„Ø¬Ø³Ù…ØŒ Ø§Ù„Ø°ÙŠÙˆÙ„ØŒ Ø§Ù„ØªÙ‚Ù„Ø¨"""
    metrics = []
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© dictionaries Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
    candle_list = []
    for candle in candles:
        if isinstance(candle, dict):
            candle_list.append(candle)
        elif isinstance(candle, (list, tuple, np.ndarray)):
            candle_list.append({
                'open': float(candle[0]),
                'high': float(candle[1]),
                'low': float(candle[2]),
                'close': float(candle[3])
            })
    
    for candle in candle_list:
        body = abs(candle['close'] - candle['open'])
        upper_wick = candle['high'] - max(candle['close'], candle['open'])
        lower_wick = min(candle['close'], candle['open']) - candle['low']
        range_price = candle['high'] - candle['low']
        price = (candle['open'] + candle['close']) / 2
        
        body_pct = (body / price * 100) if price > 0 else 0
        volatility = (range_price / price * 100) if price > 0 else 0
        
        metrics.append({
            'body_pct': body_pct,
            'volatility': volatility
        })
    
    return metrics

# ==============================================================================
# Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ (Ù…Ø­Ø³Ù‘Ù†)
# ==============================================================================
def calculate_similarity(current_candles, reference_patterns):
    """Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø´Ù…ÙˆØ¹ Ù…Ø¹ ÙØ­Øµ Ø§Ù„Ø´ÙƒÙ„ + Ø§Ù„ØªÙ‚Ù„Ø¨ + Ø§Ù„Ø£Ø¬Ø³Ø§Ù…"""
    if not reference_patterns: 
        return 0, "None"
    
    current_fingerprint = normalize_pattern(current_candles)
    current_metrics = get_candle_metrics(current_candles)
    best_score = 0
    best_name = "None"
    
    for name, ref_fingerprint in reference_patterns.items():
        if current_fingerprint.shape != ref_fingerprint.shape: 
            continue
        
        # 1ï¸âƒ£ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù…
        diff = np.mean(np.abs(current_fingerprint - ref_fingerprint))
        pattern_score = 100 * (1 - diff)
        
        # 2ï¸âƒ£ ÙØ­Øµ Ø§Ù„ØªÙ‚Ù„Ø¨ ÙˆØ§Ù„Ø£Ø¬Ø³Ø§Ù…
        volatility_diffs = []
        body_diffs = []
        
        for i in range(len(current_metrics)):
            if i < len(current_metrics):
                curr_vol = current_metrics[i]['volatility']
                curr_body = current_metrics[i]['body_pct']
                
                # Ø§ÙØªØ±Ø¶ Ø£Ù† ref_metrics Ù„Ù‡Ø§ Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                vol_diff = abs(curr_vol - (2.0 if name == "RIVN" else 1.0))  # ØªÙ‚Ø±ÙŠØ¨ÙŠ
                body_diff = abs(curr_body - (0.5 if name == "RIVN" else 0.3))
                
                volatility_diffs.append(vol_diff)
                body_diffs.append(body_diff)
        
        volatility_match = 100 - min(np.mean(volatility_diffs) if volatility_diffs else 100, 100)
        body_match = 100 - min(np.mean(body_diffs) * 0.5 if body_diffs else 100, 100)
        
        # Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: 60% Ø´ÙƒÙ„ + 25% ØªÙ‚Ù„Ø¨ + 15% Ø£Ø¬Ø³Ø§Ù…
        final_score = (
            pattern_score * 0.60 +
            volatility_match * 0.25 +
            body_match * 0.15
        )
        
        if final_score > best_score:
            best_score = final_score
            best_name = name
            
    return best_score, best_name

# ==============================================================================
# Ø¬Ù„Ø¨ 300 Ø³Ù‡Ù… Ù…Ù† Finviz
# ==============================================================================
def get_300_stocks_from_finviz():
    """Ø¬Ù„Ø¨ 300 Ø³Ù‡Ù… Ù…Ù† Finviz"""
    print("\n" + "="*70)
    print("ğŸ“Š Ø¬Ù„Ø¨ 300 Ø³Ù‡Ù… Ù…Ù† Finviz")
    print("="*70)
    
    try:
        url = (
            "https://elite.finviz.com/export.ashx?v=111"
            "&f=sh_price_u11,sh_float_u15,sh_curvol_o50,ta_change_u"
            "&o=-volume"
        )
        
        response = requests.get(url, headers=FINVIZ_HEADERS, timeout=15)
        csv_data = io.StringIO(response.text)
        df_all = pd.read_csv(csv_data)
        
        print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(df_all)} Ø³Ù‡Ù… Ù…Ù† Finviz")
        
        # ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¹Ø± ÙˆØ§Ù„Ø³ÙŠÙˆÙ„Ø©
        df_filtered = df_all[
            (df_all['Price'] >= 0.02) & 
            (df_all['Price'] <= 10) & 
            (df_all['Volume'] >= 200000)
        ].copy()
        
        df_filtered = df_filtered.sort_values('Volume', ascending=False).reset_index(drop=True)
        
        # Ø£Ø®Ø° Ø£ÙˆÙ„ 300 Ø³Ù‡Ù… (Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„)
        stocks = df_filtered['Ticker'].head(300).tolist()
        
        print(f"âœ… Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±: {len(stocks)} Ø³Ù‡Ù…")
        print(f"ğŸ“‹ Ø§Ù„Ø£Ø³Ù‡Ù…: {', '.join(stocks[:20])}...\n")
        
        return stocks
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ù‡Ù… Ù…Ù† Finviz: {e}")
        return []

# ==============================================================================
# Ø¬Ù„Ø¨ Ø´Ù…ÙˆØ¹ Ù…Ù† EODHD (Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ¹Ù„ÙŠ)
# ==============================================================================
def get_eodhd_candles(symbol, target_date):
    """Ø¬Ù„Ø¨ Ø´Ù…ÙˆØ¹ 1-Ø¯Ù‚ÙŠÙ‚Ø© Ù…Ù† EODHD Ù…Ù† 9:30 Ø¥Ù„Ù‰ 10:00 - ØªØ±Ø¬Ø¹ (Ø§Ù„Ø´Ù…ÙˆØ¹ØŒ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ¹Ù„ÙŠ)"""
    try:
        date_obj = datetime.combine(target_date, time(9, 30), tzinfo=ny_tz)
        start_timestamp = int(date_obj.timestamp())
        end_timestamp = int(date_obj.replace(hour=10, minute=0).timestamp())
        
        url = f"https://eodhd.com/api/intraday/{symbol}.US"
        params = {
            'api_token': EODHD_API_KEY,
            'from': start_timestamp,
            'to': end_timestamp,
            'period': '1m'
        }
        
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code != 200:
            return [], None  # ØªØ±Ø¬Ø¹ ØªØ§Ø±ÙŠØ® None
        
        csv_text = response.text
        
        if not csv_text or csv_text.count('\n') <= 1:
            return [], None
        
        try:
            df = pd.read_csv(io.StringIO(csv_text))
            
            if df.empty:
                return [], None
            
            candles = []
            actual_date = None
            
            for _, row in df.iterrows():
                ts = int(row['Timestamp'])
                candle_time = datetime.fromtimestamp(ts, tz=pytz.UTC).astimezone(ny_tz)
                
                if actual_date is None:
                    actual_date = candle_time.date()
                
                candles.append({
                    'datetime': candle_time,
                    'symbol': symbol,
                    'open': float(row['Open']),
                    'high': float(row['High']),
                    'low': float(row['Low']),
                    'close': float(row['Close']),
                    'volume': int(row['Volume']),
                    'time': candle_time.strftime('%Y-%m-%d %H:%M:%S')
                })
            
            return candles, actual_date  # ØªØ±Ø¬Ø¹ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ¹Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            
        except Exception as e:
            return [], None
            
    except Exception as e:
        return [], None

# ==============================================================================
# ÙØ­Øµ Ø§Ù„Ø°ÙŠÙ„ Ø§Ù„Ø·ÙˆÙŠÙ„ ÙÙŠ Ø¢Ø®Ø± Ø´Ù…Ø¹ØªÙŠÙ†
# ==============================================================================
def has_long_tail_in_last_candles(candles):
    """
    ÙØ­Øµ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø°ÙŠÙ„ Ø·ÙˆÙŠÙ„ ÙÙŠ Ø¢Ø®Ø± Ø´Ù…Ø¹ØªÙŠÙ†
    Ø§Ù„Ø´Ù…Ø¹Ø© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø°ÙŠÙ„ Ø·ÙˆÙŠÙ„ = Ø¥Ø´Ø§Ø±Ø© ØªØ­Ø°ÙŠØ± (Ø¹Ø¯Ù… Ø§Ø³ØªÙ‚Ø±Ø§Ø±)
    """
    if len(candles) < 2:
        return False
    
    # Ø¢Ø®Ø± Ø´Ù…Ø¹ØªÙŠÙ†
    last_candles = candles[-2:]
    
    for candle in last_candles:
        body = abs(candle['close'] - candle['open'])
        tail = candle['high'] - max(candle['close'], candle['open'])
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø´Ù…Ø¹Ø© ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ø¬Ø³Ù… (Ø£ÙƒØ«Ø± Ù…Ù† 0.5% Ù…Ù† Ø§Ù„Ø³Ø¹Ø±) ÙˆÙÙŠÙ‡Ø§ Ø°ÙŠÙ„ Ø·ÙˆÙŠÙ„
        price = (candle['open'] + candle['close']) / 2
        body_percent = (body / price) * 100 if price > 0 else 0
        tail_percent = (tail / body) * 100 if body > 0 else 0
        
        # Ø´Ù…Ø¹Ø© ÙƒØ¨ÙŠØ±Ø© (Ø¬Ø³Ù… > 0.3%) + Ø°ÙŠÙ„ Ø·ÙˆÙŠÙ„ (Ø£Ø·ÙˆÙ„ Ù…Ù† 50% Ù…Ù† Ø§Ù„Ø¬Ø³Ù…)
        if body_percent > 0.3 and tail_percent > 50:
            return True
    
    return False

# ==============================================================================
# ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø´Ù…ÙˆØ¹ 5 Ø¯Ù‚Ø§Ø¦Ù‚
# ==============================================================================
def aggregate_to_5min(candles):
    """ØªØ­ÙˆÙŠÙ„ Ø´Ù…ÙˆØ¹ 1-Ø¯Ù‚ÙŠÙ‚Ø© Ø¥Ù„Ù‰ 5-Ø¯Ù‚Ø§Ø¦Ù‚"""
    if not candles:
        return []
    
    df = pd.DataFrame(candles)
    df['datetime'] = pd.to_datetime(df['datetime'])
    
    # ØªØ¬Ù…ÙŠØ¹ 5 Ø¯Ù‚Ø§Ø¦Ù‚
    df_5min = df.set_index('datetime').resample('5min').agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }).dropna(subset=['close'])
    
    if df_5min.empty:
        return []
    
    result = []
    for datetime_idx, row in df_5min.iterrows():
        result.append({
            'open': float(row['open']),
            'high': float(row['high']),
            'low': float(row['low']),
            'close': float(row['close']),
        })
    
    return result

# ==============================================================================
# Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==============================================================================
print("="*70)
print("ğŸ”¬ Ø§Ø®ØªØ¨Ø§Ø± 300 Ø³Ù‡Ù… Ù…Ù† Finviz Ù…Ø¹ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ù†Ù…Ø§Ø·")
print("="*70)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
patterns = load_successful_patterns()

if not patterns:
    print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ù†Ù…Ø§Ø· Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
    exit(1)

# Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ù‡Ù… Ù…Ù† Finviz
stocks = get_300_stocks_from_finviz()

if not stocks:
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø¬Ù„Ø¨ Ø£Ø³Ù‡Ù…")
    exit(1)

# ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (22 Ùˆ 23 Ø¯ÙŠØ³Ù…Ø¨Ø± - ØªÙˆØ§Ø±ÙŠØ® Ù…Ø®ØªÙ„ÙØ© Ø¹Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· 19 Ø¯ÙŠØ³Ù…Ø¨Ø±)
# Ø³Ù†Ø­Ø§ÙˆÙ„ 22 Ø£ÙˆÙ„Ø§Ù‹ØŒ ÙˆØ¥Ø°Ø§ Ù…Ø§ ÙÙŠÙ‡ Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø­Ø§ÙˆÙ„ 23
test_dates = [
    datetime(2025, 12, 22).date(),  # Ø£Ù…Ø³ (Ø§Ù„Ø§Ø«Ù†ÙŠÙ†)
    datetime(2025, 12, 23).date(),  # Ø§Ù„ÙŠÙˆÙ… (Ø§Ù„Ø«Ù„Ø§Ø«Ø§Ø¡)
]
target_date = test_dates[0]  # Ø§Ø¨Ø¯Ø£ Ø¨Ù€ 22

print("\n" + "="*70)
print(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø´Ù…ÙˆØ¹ Ù„Ù€ {len(stocks)} Ø³Ù‡Ù…")
print(f"ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®: {target_date}")
print(f"â° Ø§Ù„ÙØªØ±Ø©: 9:30 - 10:00 AM")
print("="*70 + "\n")

successful_stocks = []
total_analyzed = 0
all_candles_5min = []  # Ù„Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ù…ÙˆØ¹

for idx, symbol in enumerate(stocks, 1):
    print(f"[{idx}/{len(stocks)}] ğŸ” {symbol:<6}", end=" ", flush=True)
    
    # Ø¬Ù„Ø¨ Ø§Ù„Ø´Ù…ÙˆØ¹ (Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø£ÙˆÙ„ØŒ ÙˆØ¥Ø°Ø§ ÙØ´Ù„ Ø­Ø§ÙˆÙ„ Ø§Ù„Ø«Ø§Ù†ÙŠ)
    candles, actual_date = get_eodhd_candles(symbol, target_date)
    used_date = actual_date  # Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ¹Ù„ÙŠ
    
    # Ø¥Ø°Ø§ Ù…Ø§ ÙÙŠÙ‡ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø£ÙˆÙ„ØŒ Ø¬Ø±Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø«Ø§Ù†ÙŠ
    if not candles or len(candles) < 3:
        if target_date == test_dates[0] and len(test_dates) > 1:
            candles, actual_date = get_eodhd_candles(symbol, test_dates[1])
            used_date = actual_date
        
        if not candles or len(candles) < 3:
            print("âŒ Ø¨Ø¯ÙˆÙ† Ø¨ÙŠØ§Ù†Ø§Øª")
            continue
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ 5 Ø¯Ù‚Ø§Ø¦Ù‚
    candles_5min = aggregate_to_5min(candles)
    
    if not candles_5min or len(candles_5min) < 3:
        print("âŒ Ø´Ù…ÙˆØ¹ ØºÙŠØ± ÙƒØ§ÙÙŠØ©")
        continue
    
    # ğŸ”´ ÙØ­Øµ Ø§Ù„Ø°ÙŠÙ„ Ø§Ù„Ø·ÙˆÙŠÙ„ - Ø¥Ø°Ø§ Ø¢Ø®Ø± Ø´Ù…Ø¹ØªÙŠÙ† ÙÙŠÙ‡Ù…Ø§ Ø°ÙŠÙ„ Ø·ÙˆÙŠÙ„ = ØªØ¬Ø§Ù‡Ù„
    if has_long_tail_in_last_candles(candles_5min):
        print("âš ï¸ Ø°ÙŠÙ„ Ø·ÙˆÙŠÙ„ (ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚)")
        continue
    
    # Ø­ÙØ¸ Ø§Ù„Ø´Ù…ÙˆØ¹
    for idx, candle in enumerate(candles_5min):
        all_candles_5min.append({
            'symbol': symbol,
            'open': candle['open'],
            'high': candle['high'],
            'low': candle['low'],
            'close': candle['close'],
            'datetime': datetime.now(ny_tz).strftime('%Y-%m-%d'),
            'time': f"{idx+1}"
        })
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ·Ø§Ø¨Ù‚
    pattern_data = np.array([[c['open'], c['high'], c['low'], c['close']] for c in candles_5min])
    match_score, match_name = calculate_similarity(pattern_data, patterns)
    
    total_analyzed += 1
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚ (Ø£Ø¯Ù†Ù‰ Ø­Ø¯ 80%)
    if match_score >= 80:
        print(f"âœ… ØªØ·Ø§Ø¨Ù‚ {match_score:.1f}% Ù…Ø¹ {match_name} [{used_date}]")
        successful_stocks.append({
            'symbol': symbol,
            'match_score': match_score,
            'match_name': match_name,
            'data_date': used_date  # Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®
        })
    else:
        print(f"âš ï¸ {match_score:.1f}%")
    
    time_module.sleep(0.1)

# ==============================================================================
# Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
# ==============================================================================
print("\n" + "="*70)
print("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
print("="*70)
print(f"âœ… Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù…Ø­Ù„Ù„Ø©: {total_analyzed}")
print(f"ğŸ¯ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù†Ø§Ø¬Ø­Ø© (80%+): {len(successful_stocks)}\n")

if successful_stocks:
    print("ğŸ† Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù†Ø§Ø¬Ø­Ø©:")
    print("-"*90)
    print(f"{'Ø§Ù„Ø³Ù‡Ù…':<10} {'Ø§Ù„ØªØ·Ø§Ø¨Ù‚':<12} {'Ø§Ù„Ù†Ù…Ø·':<10} {'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª':<20}")
    print("-"*90)
    for stock in sorted(successful_stocks, key=lambda x: x['match_score'], reverse=True):
        data_date = stock.get('data_date', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')
        print(f"  âœ… {stock['symbol']:<8} | {stock['match_score']:>5.1f}% | {stock['match_name']:<10} | {str(data_date):<20}")
else:
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø³Ù‡Ù… ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø¨Ù†Ø³Ø¨Ø© 80% ÙØ£Ø¹Ù„Ù‰")

# Ø­ÙØ¸ Ø§Ù„Ø´Ù…ÙˆØ¹ ÙÙŠ CSV
if all_candles_5min:
    df_candles = pd.DataFrame(all_candles_5min)
    output_file = f"test_candles_{datetime.now(ny_tz).strftime('%Y%m%d_%H%M%S')}.csv"
    df_candles.to_csv(output_file, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(all_candles_5min)} Ø´Ù…Ø¹Ø© ÙÙŠ: {output_file}")

print("\n" + "="*70)
