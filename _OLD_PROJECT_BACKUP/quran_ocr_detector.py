#!/usr/bin/env python3
"""
Ø¨Ø±Ù†Ø§Ù…Ø¬ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¢ÙŠØ§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† ØµÙˆØ± Ø§Ù„Ù…ØµØ­Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR
ÙŠÙ‚Ø±Ø£ ØµÙˆØ±Ø© SVG ÙˆÙŠØ­Ø¯Ø¯ Ù…ÙˆØ§Ù‚Ø¹ ÙƒÙ„ Ø¢ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
"""

import cv2
import numpy as np
import pytesseract
from PIL import Image
import json
import sys
from pathlib import Path
from collections import defaultdict

class QuranAyahDetector:
    def __init__(self, image_path):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒØ´Ù
        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© (SVG Ø£Ùˆ PNG Ø£Ùˆ JPG)
        """
        self.image_path = Path(image_path)
        self.image = None
        self.gray = None
        self.height = 0
        self.width = 0
        self.ayahs_detected = []
        
    def load_image(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©"""
        print(f"ğŸ“‚ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {self.image_path}")
        
        if self.image_path.suffix.lower() == '.svg':
            # ØªØ­ÙˆÙŠÙ„ SVG Ø¥Ù„Ù‰ PNG Ø£ÙˆÙ„Ø§Ù‹
            from cairosvg import svg2png
            from io import BytesIO
            png_data = BytesIO()
            svg2png(bytestring=open(self.image_path, 'rb').read(), write_to=png_data)
            png_data.seek(0)
            img_array = np.frombuffer(png_data.read(), dtype=np.uint8)
            self.image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        else:
            self.image = cv2.imread(str(self.image_path))
        
        if self.image is None:
            print("âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©!")
            return False
        
        self.height, self.width = self.image.shape[:2]
        self.gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {self.width}x{self.height}")
        return True
    
    def enhance_image(self):
        """ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù€ OCR"""
        print("ğŸ”§ Ø¬Ø§Ø±ÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©...")
        
        # ØªØ·Ø¨ÙŠÙ‚ threshold
        _, binary = cv2.threshold(self.gray, 150, 255, cv2.THRESH_BINARY)
        
        # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
        denoised = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, 
                                    cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)))
        
        return denoised
    
    def detect_text_regions(self, enhanced):
        """Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù†ØµÙˆØµ (Ø§Ù„Ø¢ÙŠØ§Øª)"""
        print("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù†ØµÙˆØµ...")
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙ†ØªÙˆØ±Ø§Øª (Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù†ØµÙˆØµ)
        contours, _ = cv2.findContours(enhanced, cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        # ØªØµÙÙŠØ© Ø§Ù„ÙƒÙ†ØªÙˆØ±Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
        valid_contours = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 500:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                valid_contours.append(contour)
        
        return sorted(valid_contours, key=lambda c: cv2.boundingRect(c)[1])  # ØªØ±ØªÙŠØ¨ Ù…Ù† Ø£Ø¹Ù„Ù‰ Ù„Ø£Ø³ÙÙ„
    
    def extract_ayahs_with_ocr(self, enhanced):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¢ÙŠØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR"""
        print("ğŸ§  Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„ OCR (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªØ§Ù‹)...")
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
        custom_config = r'--oem 3 --psm 6 -l ara'
        ocr_data = pytesseract.image_to_data(enhanced, config=custom_config, 
                                             output_type=pytesseract.Output.DICT)
        
        detected_ayahs = []
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© (confidence)
        for i in range(len(ocr_data['text'])):
            if ocr_data['text'][i].strip():  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ÙØ§Ø±ØºØ©
                confidence = int(ocr_data['conf'][i])
                
                if confidence > 30:  # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ù…Ù† Ø§Ù„Ø«Ù‚Ø©
                    ayah = {
                        'text': ocr_data['text'][i],
                        'x': ocr_data['left'][i],
                        'y': ocr_data['top'][i],
                        'width': ocr_data['width'][i],
                        'height': ocr_data['height'][i],
                        'confidence': confidence
                    }
                    detected_ayahs.append(ayah)
        
        return detected_ayahs
    
    def group_ayahs_by_line(self, ayahs):
        """ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¢ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø³Ø·Ø± (Y ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ Ù…ØªØ³Ø§ÙˆÙŠ)"""
        print("ğŸ“ Ø¬Ø§Ø±ÙŠ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¢ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£Ø³Ø·Ø±...")
        
        if not ayahs:
            return []
        
        lines = defaultdict(list)
        threshold = 20  # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¢ÙŠØ§Øª Ø§Ù„Ù‚Ø±ÙŠØ¨Ø© Ø¹Ù…ÙˆØ¯ÙŠØ§Ù‹
        
        for ayah in ayahs:
            y = ayah['y']
            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£Ù‚Ø±Ø¨
            closest_line = min(lines.keys(), 
                             key=lambda k: abs(k - y), 
                             default=None) if lines else None
            
            if closest_line is None or abs(closest_line - y) > threshold:
                closest_line = y
            
            lines[closest_line].append(ayah)
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¢ÙŠØ§Øª Ø¯Ø§Ø®Ù„ ÙƒÙ„ Ø³Ø·Ø± Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø± (Ø¹Ø±Ø¨ÙŠ)
        for line in lines.values():
            line.sort(key=lambda a: a['x'], reverse=True)
        
        return sorted(lines.items(), key=lambda x: x[0])
    
    def extract_ayah_numbers(self, grouped_ayahs):
        """Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¢ÙŠØ§Øª"""
        print("ğŸ”¢ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¢ÙŠØ§Øª...")
        
        results = []
        ayah_counter = 1
        
        for line_y, ayahs_in_line in grouped_ayahs:
            for ayah in ayahs_in_line:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ù‚Ù… Ù…Ù† Ø§Ù„Ù†Øµ
                text = ayah['text'].strip()
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø±Ù‚Ø§Ù… Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
                numbers = ''.join(filter(str.isdigit, text))
                
                if numbers:
                    ayah_num = int(numbers)
                else:
                    ayah_num = ayah_counter
                
                result = {
                    'ayah_number': ayah_num,
                    'text': text,
                    'x': ayah['x'],
                    'y': ayah['y'],
                    'width': ayah['width'],
                    'height': ayah['height'],
                    'confidence': ayah['confidence']
                }
                results.append(result)
                ayah_counter = ayah_num + 1
        
        return results
    
    def visualize_results(self, output_path=None):
        """Ø±Ø³Ù… ØµÙˆØ±Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¨Ø§Ù„Ø¢ÙŠØ§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©"""
        print("ğŸ¨ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ©...")
        
        if output_path is None:
            output_path = self.image_path.parent / f"{self.image_path.stem}_detected.jpg"
        
        annotated = self.image.copy()
        
        # Ø±Ø³Ù… ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø­ÙˆÙ„ ÙƒÙ„ Ø¢ÙŠØ©
        for ayah in self.ayahs_detected:
            x, y = ayah['x'], ayah['y']
            w, h = ayah['width'], ayah['height']
            
            # Ø§Ù„Ù„ÙˆÙ† Ø­Ø³Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©
            confidence = ayah['confidence']
            color = (0, 255, 0) if confidence > 60 else (0, 165, 255)
            
            # Ø±Ø³Ù… Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚
            cv2.rectangle(annotated, (x, y), (x + w, y + h), color, 2)
            
            # ÙƒØªØ§Ø¨Ø© Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©
            cv2.putText(annotated, str(ayah['ayah_number']), 
                       (x + 5, y + 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        cv2.imwrite(str(output_path), annotated)
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©: {output_path}")
        return output_path
    
    def save_results(self, output_path=None):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ JSON"""
        if output_path is None:
            output_path = self.image_path.parent / f"{self.image_path.stem}_ayahs.json"
        
        data = {
            'image_file': str(self.image_path),
            'image_size': {
                'width': self.width,
                'height': self.height
            },
            'total_ayahs_detected': len(self.ayahs_detected),
            'ayahs': self.ayahs_detected
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {output_path}")
        return output_path
    
    def process(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
        print("\n" + "="*50)
        print("ğŸ”¬ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©...")
        print("="*50 + "\n")
        
        if not self.load_image():
            return False
        
        enhanced = self.enhance_image()
        
        # Ø·Ø±ÙŠÙ‚Ø© 1: Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR Ù…Ø¨Ø§Ø´Ø±Ø©
        raw_ayahs = self.extract_ayahs_with_ocr(enhanced)
        print(f"ğŸ“Š ØªÙ… Ø§Ù„ÙƒØ´Ù Ø¹Ù† {len(raw_ayahs)} Ù…Ù†Ø·Ù‚Ø© Ù†ØµÙŠØ©")
        
        # Ø·Ø±ÙŠÙ‚Ø© 2: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙ†ØªÙˆØ±Ø§Øª
        contours = self.detect_text_regions(enhanced)
        print(f"ğŸ“ ØªÙ… Ø§Ù„ÙƒØ´Ù Ø¹Ù† {len(contours)} Ù…Ù†Ø·Ù‚Ø© Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙ†ØªÙˆØ±Ø§Øª")
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if raw_ayahs:
            grouped = self.group_ayahs_by_line(raw_ayahs)
            self.ayahs_detected = self.extract_ayah_numbers(grouped)
        
        if not self.ayahs_detected:
            print("âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø¢ÙŠØ§Øª! Ø­Ø§ÙˆÙ„ ØµÙˆØ±Ø© Ø£ÙˆØ¶Ø­.")
            return False
        
        print(f"\nâœ… ØªÙ… Ø§Ù„ÙƒØ´Ù Ø¹Ù† {len(self.ayahs_detected)} Ø¢ÙŠØ©!\n")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        for ayah in self.ayahs_detected[:5]:  # Ø£ÙˆÙ„ 5 Ø¢ÙŠØ§Øª
            print(f"  â€¢ Ø¢ÙŠØ© {ayah['ayah_number']}: {ayah['text'][:30]}...")
            print(f"    Ø§Ù„Ù…ÙˆÙ‚Ø¹: x={ayah['x']}, y={ayah['y']}, Ø§Ù„Ø«Ù‚Ø©: {ayah['confidence']}%\n")
        
        if len(self.ayahs_detected) > 5:
            print(f"  ... Ùˆ {len(self.ayahs_detected) - 5} Ø¢ÙŠØ§Øª Ø£Ø®Ø±Ù‰\n")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        json_path = self.save_results()
        img_path = self.visualize_results()
        
        return True


def main():
    if len(sys.argv) < 2:
        print("Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: python quran_ocr_detector.py <image_path>")
        print("Ù…Ø«Ø§Ù„: python quran_ocr_detector.py page_003.svg")
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    detector = QuranAyahDetector(image_path)
    success = detector.process()
    
    if success:
        print("\n" + "="*50)
        print("ğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­!")
        print("="*50)
    else:
        print("\nâŒ ÙØ´Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        sys.exit(1)


if __name__ == "__main__":
    main()
